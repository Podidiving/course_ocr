{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from course_ocr_t1.data import MidvPackage\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "from typing import Dict, Tuple\n",
    "from skimage.morphology import area_closing\n",
    "import os\n",
    "\n",
    "from src.segmentation.lightning import LightningModel\n",
    "\n",
    "from course_ocr_t1.metrics import dump_results_dict, measure_crop_accuracy\n",
    "from course_ocr_t1.metrics import iou_relative_quads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_path = \"deeplabv3plus/segmentation/1652827910/segmentation-14.ckpt\"  # specify your own path\n",
    "\n",
    "model = LightningModel.load_from_checkpoint(ckpt_path, map_location=\"cpu\")\n",
    "model.eval();\n",
    "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model.to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = Path() / '..' / 'midv500_compressed'\n",
    "assert DATASET_PATH.exists(), DATASET_PATH.absolute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    BASE: int = 320\n",
    "    ORIGINAL_SHAPE: Tuple[int, int] = (800, 450)\n",
    "\n",
    "    def __init__(self, path: str, is_test: bool = False):\n",
    "        super().__init__()\n",
    "        self.path = Path(path)\n",
    "        self.is_test = is_test\n",
    "        self.images = None\n",
    "        self.masks = None\n",
    "        self.keys = None\n",
    "        self._init()\n",
    "\n",
    "    def _init(self):\n",
    "        data_packs = MidvPackage.read_midv500_dataset(self.path)\n",
    "        self.images = []\n",
    "        self.masks = []\n",
    "        self.keys = []\n",
    "        for pack in data_packs:\n",
    "            for di in pack:\n",
    "                if self.is_test == di.is_test_split() and di.is_correct():\n",
    "                    self.images.append(di.img_path)\n",
    "                    self.masks.append(np.array(di.gt_data[\"quad\"]))\n",
    "                    self.keys.append(di.unique_key)\n",
    "        self.images = np.array(self.images)\n",
    "        self.masks = np.array(self.masks)\n",
    "        self.keys = np.array(self.keys)\n",
    "        self.h_pad = (self.BASE * 3 - self.ORIGINAL_SHAPE[0]) // 2\n",
    "        self.w_pad = (self.BASE * 2 - self.ORIGINAL_SHAPE[1]) // 2\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, item: int) -> Dict[str, np.ndarray]:\n",
    "        tmp = cv2.imread(str(self.path / self.images[item]))[:, :, ::-1]\n",
    "\n",
    "        image = np.zeros((self.BASE * 3, self.BASE * 2, 3), dtype=np.uint8)\n",
    "        image[self.h_pad:tmp.shape[0] + self.h_pad, self.w_pad: tmp.shape[1] + self.w_pad] = tmp\n",
    "        \n",
    "        image = torch.permute(torch.from_numpy(image).float(), (2, 0, 1)) / 255.\n",
    "        return {\n",
    "            \"image\": image,\n",
    "            \"mask\": self.masks[item],\n",
    "            \"key\": self.keys[item]\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "dataset = Dataset(DATASET_PATH, True)\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ious = []\n",
    "result = {}\n",
    "idx = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 25/266 [02:23<22:05,  5.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9771624118328396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 50/266 [04:39<19:37,  5.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9775590479454631\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 75/266 [06:58<17:48,  5.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9777399498438721\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 100/266 [09:16<16:11,  5.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9785266707786286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 125/266 [11:37<12:52,  5.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9776938350261406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▋    | 150/266 [13:59<10:24,  5.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9771373022349827\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 175/266 [16:25<09:01,  5.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9776889793926895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 200/266 [18:46<06:18,  5.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9779303939735113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▍ | 225/266 [21:10<04:01,  5.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9739944424153301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 250/266 [23:31<01:29,  5.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9713333940186761\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 266/266 [25:01<00:00,  5.65s/it]\n"
     ]
    }
   ],
   "source": [
    "global_batch = idx\n",
    "\n",
    "with torch.no_grad():\n",
    "    for idx, batch in tqdm(enumerate(dataloader), total=len(dataloader)):\n",
    "        if global_batch > idx:\n",
    "            continue\n",
    "        image = batch[\"image\"].to(device)\n",
    "        res = model(image)\n",
    "        for in_batch_idx in range(batch_size):\n",
    "            if in_batch_idx >= len(res):\n",
    "                break\n",
    "            pred = (res[in_batch_idx] > 0.5).float()[0]\n",
    "            pred = pred[\n",
    "                dataset.h_pad:dataset.ORIGINAL_SHAPE[0] + dataset.h_pad,\n",
    "                dataset.w_pad:dataset.w_pad + dataset.ORIGINAL_SHAPE[1]\n",
    "            ].cpu().numpy()\n",
    "            pred = area_closing(pred)\n",
    "            cnts = cv2.findContours(\n",
    "                pred.astype(np.uint8).copy(),\n",
    "                cv2.RETR_TREE,\n",
    "                cv2.CHAIN_APPROX_SIMPLE\n",
    "            )[0]\n",
    "            cnt_idx = 0\n",
    "            if len(cnts) == 0:\n",
    "                result[batch[\"key\"][in_batch_idx]] = [\n",
    "                    [0.0, 0.0],\n",
    "                    [0.0, 1.0],\n",
    "                    [1.0, 1.0],\n",
    "                    [1.0, 0.0]\n",
    "                ]\n",
    "                continue\n",
    "            if len(cnts) > 1:\n",
    "                max_perimeter = -1\n",
    "                for cnt_idx_ in range(len(cnts)):\n",
    "                    perimeter = cv2.arcLength(cnts[cnt_idx_], True)\n",
    "                    if perimeter > max_perimeter:\n",
    "                        cnt_idx = cnt_idx_\n",
    "                        max_perimeter = perimeter\n",
    "            perimeter = cv2.arcLength(cnts[cnt_idx], True)\n",
    "            poly_curve = cv2.approxPolyDP(cnts[cnt_idx], 0.01 * perimeter, True)\n",
    "            poly = poly_curve[:, 0].astype(float)\n",
    "            if len(poly) < 3:\n",
    "                result[batch[\"key\"][in_batch_idx]] = [\n",
    "                    [0.0, 0.0],\n",
    "                    [0.0, 1.0],\n",
    "                    [1.0, 1.0],\n",
    "                    [1.0, 0.0]\n",
    "                ]\n",
    "                continue\n",
    "            gt = batch[\"mask\"][in_batch_idx].numpy().astype(float)\n",
    "            gt[:, 0] /= dataset.ORIGINAL_SHAPE[1]\n",
    "            gt[:, 1] /= dataset.ORIGINAL_SHAPE[0]\n",
    "            p = poly.copy()\n",
    "            p[:, 0] /= dataset.ORIGINAL_SHAPE[1]\n",
    "            p[:, 1] /= dataset.ORIGINAL_SHAPE[0]\n",
    "            ious.append(iou_relative_quads(gt, p))\n",
    "            result[batch[\"key\"][in_batch_idx]] = p.tolist()\n",
    "        if (idx + 1) % 25 == 0:\n",
    "            print(np.array(ious).mean())\n",
    "        global_batch += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump_results_dict(result, Path() / \"pred.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
